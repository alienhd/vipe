defaults:
  - /slam: default

instance: vipe.pipeline.colorization.VideoColorizationPipeline

# Init configs
init:
  camera_type: "pinhole"
  intrinsics: "geocalib"
  instance:
    kf_gap_sec: 2.0
    phrases: 
      - person
      - animal
      - vehicle
      - ball
      - balloon
      - gun
      - pet
      - car
      - bus
    add_sky: true

slam:
  keyframe_depth: unidepth-l
  optimize_intrinsics: ${neq:${..init.intrinsics},"gt"}

# Post-processing configs
post:
  depth_align_model: "adaptive_unidepth-l_svda"

# Colorization specific configs
colorization:
  # Model configurations
  depth_model: "LiheYoung/depth-anything-small-hf"
  semantic_model: "openmmlab/upernet-convnext-small"
  colorization_model: "runwayml/stable-diffusion-inpainting"
  
  # Processing parameters
  device: "cuda"
  batch_size: 1
  inference_steps: 20
  guidance_scale: 7.5
  
  # Temporal consistency parameters
  temporal_weight: 0.3
  semantic_consistency: true
  depth_conditioning: true
  
  # Point cloud parameters
  point_cloud_density: 1000
  semantic_filtering: true

# Output configs
output:
  # Path to save results
  path: colorization_results/
  skip_exists: false

  # Save artifacts and a info file
  save_artifacts: true
  save_intermediate: true

  # Save colorization specific outputs
  save_depth_maps: true
  save_semantic_masks: true
  save_point_clouds: true
  save_colorized_frames: true

  # Visualization videos to BASE_PATH/colorization/xxx.mp4
  save_viz: true
  viz_downsample: 2
  viz_attributes: [['rgb', 'depth'], ['semantic', 'colorized']]